** 6.6 선형 모델의 응용
   Ax=b 대신에 X\beta=y 를 사용한다.
   X는 계획행렬(Design matrix), \beta는 매개변수 벡터, y는 관측벡터(observed verctor)라고 부른다.
*** 최소제곱직선
    2차원 공간 그래프에 분포된 점들이 무리를 이루어 마치 옅은 직선이나 곡선처럼 보이는 경우가 있다.
    이러한 점들에 가급적 가장 근접한 직선이나 곡선을 구하는 것이 필요할 때가 있다.
    여기서는 직선에 대해서 다루어 본다.
    이러한 직선은 일차방정식 y=\beta_{0} + \beta_{1}x 형태가 된다.
    (\beta_{0}는 직선의 높이, \beta_{1}는 직선의 기울기)
    
    그래프의 실제 점은 *자료값 내지는 관측값* 이고 
    이 점에 가까운 직선 위의 점은 *예상값(predicted value)* 이라 부른다.
    그리고 관측값과 예상값의 차이를 *잉여(residual)* 라고 부른다.

    직선과 관측값의 근사 정도를 측정하는 일반적 방법은 잉여들의 제곱을 합하는 것이다.
    (잉여는 사실상 거리이고 이 거리의 전체 합이 작을 수록 전체적으로 더 가깝다고 판단 할 수 있다.)

    *최소제곱직선(least squares line)* 이란 잉여들의 제곱의 합이 최소화되는 직선으로 
    그 공식은 역시 y=\beta_{0} + \beta_{1}x 이다.

    최소제곱직선은 관측점의 오차가 y좌표에만 생긴다고 가정하므로
    *x위에 y의 회귀직선(line of regression of y on x)* 이라고도 부른다.
    \beta_{0}, \beta_{1} 은 *회귀계수(regression coefficients)* 라고 한다.

    만약에 관측값과 예상값의 오차가 없다면 최소제곱직선은 X\beta=y 형태로 바꿀 수 있다.
    관측값과 예상값의 오차가 있어도 여전히 X\beta=y로 바꿀 수는 있다.
    하지만 해는 없다. 그렇다면 근사해를 구하는 문제가 되니 표현만 달라진 최소제곱법 문제가 된다.
    
    X\beta=y의 최소제곱해 계산과 최소제곱직선을 결정하는 \beta를 구하는 것은 동치이다.
    따라서 최소제곱문제의 정규방정식을 이용하여 최소제곱해 \beta를 구할 수 있다.
 
    현실적으로 사용되는 방법은 *평균편차 형식(mean deviation form)* 으로 x를 바꾸어 
    계획행렬의 열들이 직교관계가 되게 하여 QR분해를 이용한 최소제곱법으로 간단하게 푸는 것이다.

    평균편차 형식은 x값들의 평균을 구하여 개별 원본x값과 평균x값(\overline{x})의 차이값(x^{*})을 구하는 것이다.

*** 일반 선형 모델
    최소제곱직선을 넘어선 것들과의 근사를 표현하는 일반화된 모델이 필요하다.
    그것이 *선형 모델* 이며 y = X\beta + \epsilon 으로 정리된다.
    \epsilon이 잉여를 모은 잉여벡터이다.
    그러므로 잉여벡터가 사실상 근사의 정도인데 
    이것을 좌우하는 것은 여전히 베타이다.
    따라서 여전히 X\beta=y 로 최소제곱해를 풀 수 있고
    X^{T}X\beta = X^{T}y 정규방정식으로 베타를 구할 수 있다.

    아래 나머지는 일반 선형 모델을 잡아내는 사례들을 다룬다.

*** 곡선으로의 최소제곱근사
    곡선의 일반적인 형태를 나타내는 방정식은 다음과 같다.

      \[ y = \beta_{0}f_{0}(x) + \beta_{1}f_{1}(x) + \cdots + \beta_{k}f_{k}(x) \]

    여기서 함수들은 모두 제시되고 베타들은 미지수이다.  

*** 중다회귀(multiple regression)
    개념이나 용도에 대한 설명은 없다.
    두 개의 독립변수 u,v와 한 개의 종속변수 y를 가질 경우 단순한 방정식과 일반적인 방정식이 아래처럼 예측된다.

       y=\beta_{0} + \beta_{1}u + \beta_{2}v

       y=\beta_{0} + \beta_{1}u + \beta_{2}v + \beta_{3}u^{2} + \beta_{4}uv + \beta_{5}v^{2} 

    이런 방정식은 지질학에서 사용되며 이 방정식의 최소제곱근사를 특별히 *경향표면(trend surface)* 라고 부른다.   
    어떻게 2차항이 있는데 선형 모델이라는 것인가 의문인데
    매개변수들에 관하여 선형이므로 선형 모델이라고 한다. 

    위에서 본 것에서 한 걸음 더 나아간 선형 모델은 아래처럼 각 항에 아예 함수가 자리잡은 것이다.
      
       \[ y= \beta_{0}f_{0}(u,v) + \beta_{1}f_{1}(u,v) + \cdots + \beta_{k}f_{k}(u,v) \]

    지리학에서 위도, 경도, 고도를 항으로 하는 선형 모델의 최소제곱근사는 *최소제곱평면(least squares plane)* 이라 한다.   
